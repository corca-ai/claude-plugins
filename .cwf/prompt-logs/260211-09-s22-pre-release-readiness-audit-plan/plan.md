# S22 Pre-Release Readiness Audit Plan

## Task
"저는 이런 것들을 생각해봤습니다.
1. 전체 대상으로 refactor --docs, --holistic, --code 돌리기 (플래그 또 있나요?)
2. 리드미에 cwf 의 설계 철학과 구조, 핵심 컨셉들(다니엘 잭슨의 컨셉)이 충분히 잘 드러나있는지 검토하기
3. 에이전트 엠디에서부터 시작하는, 그리고 플러그인 디렉토리 내에서의 문서 발견 구조가 적절한지 (이 리포의 자기완결성, 플러그인의 자기완결성), 그리고 애초에 좋은 문서인지 검토하기. (1의 부분집합 같긴 하지만)
4. cwf 첫 설치한 유저 입장에서, 그래서 뭐부터 해야 하고, 뭘 하고 싶으면 어떤 스킬을 호출하면 되는지(어떤 스킬/훅/스크립트가 뭘 위해 존재하는지 포함). 그걸 하면 실제로 어떤 일이 어떤 순서로 일어나는지 아주 디테일한 시나리오로 따라가보기.

의견이 궁금합니다. 이걸 위한 플랜을 지금 세션에서 세우고 넘어가도 될 것 같고요."

## Execution Contract (Plan Mention-Only Safe)

If the user mentions only this `plan.md`, treat that as an instruction to execute
this S22 audit plan in two phases (do not respond with plan restatement only).

- Required mode: quality-first audit execution (depth over speed)
- Branch gate:
  - Before implementation edits, check current branch.
  - If on `main`/`master` (or repo primary branch), create/switch to a feature branch.
- Commit gate:
  - Commit in meaningful units during execution (per work item/change pattern).
  - Stage only intended files for each commit unit.
- Phase A (autonomous): complete user concerns 1-3
  - full refactor evidence pass
  - full scripts audit
  - README framing audit
  - discoverability architecture audit
- Phase B (handoff prep): generate interactive Step 4 prompt package
  - create a prompt the user can run with the agent to do the onboarding walkthrough together
  - stop after prompt generation and wait for user
- Required deliverables in this run:
  - `refactor-evidence.md`
  - `skill-coverage-matrix.md`
  - `script-coverage-matrix.md`
  - `readme-framing-audit.md`
  - `discoverability-audit.md`
  - `readiness-prestep4.md`
  - `step4-interactive-prompt.md`
- Deferred deliverables (interactive step with user):
  - `onboarding-scenario.md`
  - `readiness-report.md` (final Go/No-Go)
- Completion policy for this run:
  - explicit pass/fail status for concerns 1-3
  - no final Go/No-Go before interactive Step 4
  - run `scripts/check-session.sh --impl` once session artifacts are registered

## Scope Summary
- **Goal**: Build a release-readiness evidence package that validates all CWF skills, all runtime scripts, documentation quality, discoverability, architectural coherence, and first-user onboarding flow.
- **Key Decisions**:
  - Audit order: broad automated scans first vs scenario-first deep walkthrough.
  - Evidence policy: rely on `cwf:refactor` outputs only vs hybrid (`refactor` + manual walkthrough).
  - Release gate: advisory findings vs hard go/no-go criteria.
  - Execution model: quality-first depth (sequential or small-batch) over throughput.
- **Known Constraints**:
  - Current branch has uncommitted session logs generated by tooling; avoid destructive cleanup.
  - `/review` and `/refactor` are instruction-driven workflows, so outputs may require spot-checking.
  - Korean communication for user-facing reports, English for artifacts.

## Context
The current branch already includes major behavioral changes (env loader standardization + review provider routing). Before final release, we need confidence that users can discover and operate CWF without tribal knowledge. Existing project documentation already encodes core principles (progressive disclosure, docs-as-code, concept integrity), but we need execution-level validation from a first-user perspective.

Prior art used in this planning step:
- `docs/documentation-guide.md` (compressed index, scoped docs, instruction budget)
- `docs/architecture-patterns.md` (shared patterns, session/hook constraints)
- `plugins/cwf/skills/refactor/SKILL.md` (multi-mode systematic review)

## Goal
Produce a single pre-release readiness report with pass/fail evidence for:
1. Refactor-based structural quality signals (`--docs`, `--holistic`, `--code`, and full-skill deep reviews)
2. README concept communication quality (CWF philosophy + Daniel Jackson concept clarity)
3. README framing completeness:
   - What this plugin **is**
   - What this plugin **is not**
   - Core assumptions/premises
   - Core decisions and rationale
4. Discoverability architecture quality (AGENTS entry path and plugin self-containment)
5. First-install user journey fidelity (what to run first, expected sequence and outcomes)
6. Full script-level quality coverage (hooks, skill scripts, top-level automation scripts)

## Scope
Included:
- Run and analyze `cwf:refactor` modes relevant to docs/system coherence.
- Run deep review for **all 11 CWF skills** (not sampled).
- Review **all relevant scripts** under plugin and repository automation paths.
- Audit README/README.ko messaging and conceptual traceability.
- Audit whether README explicitly communicates scope boundaries and decision rationale
  ("is / is not", assumptions, decisions, reasons).
- Audit entry-point docs map (`AGENTS.md` -> `cwf-index.md` -> docs/plugin references).
- Execute detailed first-user walkthrough scenario and record friction points.
- Produce release readiness verdict with blocking/non-blocking findings.

Excluded:
- Implementing all discovered fixes in this same session.
- Non-CWF plugin migration work.
- Broad feature expansion unrelated to release readiness.

## Commit Strategy
- **Per change pattern**
  - Commit A: Audit artifacts and readiness report.
  - Commit B: Any deterministic guard additions (if approved after findings).

Rationale: This is cross-cutting analysis work where files span docs, skills, and session artifacts.

## Steps
1. **Audit framing and evidence schema**
   - Define evaluation dimensions, severity levels, and release gate criteria.
   - Create a checklist matrix shared by all later steps.

2. **Run refactor evidence passes (full coverage)**
   - Execute `cwf:refactor --docs`.
   - Execute `cwf:refactor --holistic` (or `cwf:refactor --skill --holistic` equivalent).
   - Execute `cwf:refactor --skill <name>` for all 11 skills:
     - `setup`, `update`, `gather`, `clarify`, `plan`, `impl`, `retro`, `refactor`, `handoff`, `ship`, `review`.
   - Execute `cwf:refactor --code` for recent commit range context.
   - Normalize outputs into comparable findings (blocking vs advisory).
   - Produce a flag grammar matrix (composable vs mutually exclusive vs alias).

3. **Run script-wide code quality audit (full scripts coverage)**
   - Target paths:
     - `plugins/cwf/hooks/scripts/*`
     - `plugins/cwf/skills/*/scripts/*`
     - `scripts/*`
     - `scripts/codex/*`
   - Use a two-layer approach:
     - deterministic checks first (`bash -n`, `node --check`, policy greps)
     - deep manual risk analysis with strict synthesis/spot-checking (parallel only when it preserves review quality).
   - Merge findings with file-level references and severity tags.

4. **README philosophy, boundary, and rationale review**
   - Evaluate whether CWF architecture, philosophy, and Daniel Jackson concept framing are discoverable and actionable.
   - Verify explicit framing exists for:
     - what CWF is
     - what CWF is not
     - core assumptions/premises
     - major decisions and why they were made
   - Check if README and README.ko provide equivalent conceptual affordance.
   - Produce a concrete README section proposal if any framing element is missing.

5. **Discoverability architecture review (independent gate, not duplicate)**
   - Trace entry path from `AGENTS.md` and `cwf-index.md` to plugin-local docs.
   - Evaluate repository self-containment vs plugin self-containment boundaries.
   - Identify dead ends, circular reads, or over-long hops.

6. **Pre-Step4 synthesis and interactive prompt generation**
   - Synthesize findings for concerns 1-3 only.
   - Produce a readiness snapshot with blocker/non-blocking classification scoped to 1-3.
   - Generate a high-fidelity interactive prompt for Step 4 walkthrough.
   - Stop after prompt generation and wait for user.

7. **Interactive first-user walkthrough and final gate (deferred)**
   - Run Step 4 together with the user in the next interactive phase.
   - Then produce final Go/No-Go recommendation.

## Success Criteria

### Behavioral (BDD)

```gherkin
Given the current branch state and documentation set
When the audit plan is executed end-to-end
Then each of the four user-proposed concerns has explicit evidence and verdict

Given refactor modes are run for docs/holistic/code
When findings are consolidated
Then the report distinguishes blockers from advisories with file-level references

Given a first-install user scenario is replayed
When onboarding steps are executed in sequence
Then required commands, expected outputs, and failure points are documented in actionable order

Given release readiness is evaluated
When synthesis is completed
Then a clear Go/No-Go recommendation with rationale is produced

Given README quality is part of release criteria
When README/README.ko are reviewed
Then the report includes explicit pass/fail verdicts for "is/is-not", assumptions, decisions, and rationale visibility

Given full-coverage review is required
When the audit completes
Then all 11 skills and all target script paths have explicit review evidence and verdict status
```

### Qualitative
- The report should be understandable without prior session context.
- Findings should minimize opinion-only claims and maximize verifiable evidence.
- The release decision should be conservative when evidence conflicts.
- Korean communication output should remain concise and decision-oriented.
- README framing should reduce misinterpretation for first-time users without forcing deep prior context.
- Depth and correctness should be prioritized over speed or token efficiency.

## Files to Create/Modify

| File | Action | Purpose |
|------|--------|---------|
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/plan.md` | Create | Session plan and acceptance criteria |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/lessons.md` | Create | Planning-stage learnings |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/readiness-report.md` | Create | Final audit synthesis and release gate verdict |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/refactor-evidence.md` | Create | Consolidated refactor mode evidence |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/skill-coverage-matrix.md` | Create | All-11 skills review coverage and verdict matrix |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/script-coverage-matrix.md` | Create | Full scripts path coverage and deterministic/manual findings |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/readme-framing-audit.md` | Create | README scope/rationale audit and proposed section contract |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/discoverability-audit.md` | Create | AGENTS/index/plugin docs path and self-containment audit |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/readiness-prestep4.md` | Create | Pre-Step4 blockers/non-blocking snapshot for concerns 1-3 |
| `prompt-logs/260211-09-s22-pre-release-readiness-audit-plan/step4-interactive-prompt.md` | Create | Interactive walkthrough prompt package for user+agent session |
| `cwf-state.yaml` | Edit | Live phase/task context update |

## Don't Touch
- Historical prompt-log artifacts from prior sessions except for reference reading.
- Runtime behavior code paths unless a blocker requires immediate deterministic guard.
- Secrets, local shell profiles, and out-of-repo runtime config files.

## Deferred Actions
- [ ] Convert release blockers into an implementation-only S23 plan with explicit commit boundaries (received during planning/audit prep).
- [ ] Add deterministic regression checks for documentation discoverability if recurring failures are found (received during planning/audit prep).
- [ ] Execute interactive Step 4 walkthrough with user and finalize `onboarding-scenario.md` + `readiness-report.md`.
