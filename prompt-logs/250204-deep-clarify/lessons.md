# Lessons: deep-clarify 설계 세션

## 원칙 기반 vs 예시 기반 프롬프팅

- **Expected**: Tier 3 (사람만 결정 가능한 항목)의 기준을 명확히 하기 위해 예시를 나열하면 좋을 것
- **Actual**: 예시를 나열하면 모델이 앵커링되어 창의성이 제약됨. 단일 원칙만으로도 모델이 매 상황에서 first principles로 추론 가능
- **Takeaway**: 프롬프트에서 행동 기준을 정의할 때, 구체적 예시보다 판단 원칙을 주는 것이 더 유연한 결과를 낳음

When 스킬 프롬프트에서 판단 기준을 정의할 때 → 예시 나열 대신 원칙 하나로 표현하라

## 서브에이전트의 건설적 차이

- **Expected**: 단일 에이전트가 코드베이스 탐색 + 웹 검색을 순차적으로 하면 충분할 것
- **Actual**: 순차 실행 시 먼저 발견한 정보에 앵커링됨. 독립적 서브에이전트들의 결과를 취합하면 코드베이스 관행과 업계 베스트 프랙티스 사이의 긴장이 명시적으로 드러남
- **Takeaway**: 서로 다른 소스에서 오는 정보가 충돌할 수 있을 때, 독립 에이전트로 분리하면 그 충돌 자체가 가치 있는 신호가 됨

## 실존 전문가 페르소나의 효과

- **Expected**: "보안 전문가"처럼 일반적인 역할을 부여하면 충분할 것
- **Actual**: 실존하는 전문가의 이름(예: Bruce Schneier, Martin Fowler)으로 프롬프팅하면 모델이 훨씬 구체적이고 차별화된 응답을 생성
- **Takeaway**: 이름 기반 페르소나는 강력하지만, fabrication 리스크가 있으므로 반드시 published work에 grounding해야 함

When 베스트 프랙티스 리서치에서 전문가 관점을 활용할 때 → 먼저 웹 검색으로 실제 출처를 찾고, 거기서 식별된 전문가의 documented 관점으로 reasoning하라

## Advisory 에이전트로 Tier 3 의사결정 지원

- **Expected**: Tier 3 항목은 질문만 던지고 사람이 결정하면 됨
- **Actual**: 두 에이전트가 각각 다른 관점에서 의견을 제시하면, 사람이 훨씬 informed한 결정을 내릴 수 있음. 토큰 비용은 Tier 3 항목 수에 bounded
- **Takeaway**: 주관적 결정도 "맥락 없이 물어보기"와 "양측 의견과 함께 물어보기"는 결과 품질이 다름

## 새 플러그인 vs 메이저 버전 업데이트

- **Expected**: clarify를 v2.0.0으로 메이저 버전 업데이트
- **Actual**: 철학이 완전히 다른 스킬은 별도 플러그인(deep-clarify)으로 만드는 것이 더 깔끔. 기존 사용자에게 breaking change 없고, 사용자가 용도에 따라 선택 가능
- **Takeaway**: 동일 도메인이라도 접근 방식이 근본적으로 다르면 별도 플러그인이 낫다

When 기존 스킬을 크게 변경하려 할 때 → 철학이 다르면 새 이름의 별도 플러그인으로 분리하라

## 서브에이전트 수의 트레이드오프

- **Expected**: 더 많은 서브에이전트 = 더 나은 결과
- **Actual**: 코드베이스 탐색은 1개로 충분 (Glob/Grep/Read가 프로젝트 전체 커버). 베스트 프랙티스 도메인 분할은 "어떤 도메인이 관련 있는지" 사전 판단이 필요해 chicken-and-egg 문제 발생
- **Takeaway**: 서브에이전트 수는 "독립적 정보 소스가 몇 개인가"로 결정. 같은 소스를 여러 에이전트로 나누는 것은 오버헤드만 증가

When 서브에이전트 수를 결정할 때 → 정보 소스의 독립성을 기준으로 하라. 동일 소스의 분할보다 이질적 소스 간 병렬이 가치있음
